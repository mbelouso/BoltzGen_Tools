{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5165c1e0",
   "metadata": {},
   "source": [
    "# Notebook for filtering by minibinder location\n",
    "\n",
    "Workbook to understand mmCIF parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a48df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio.PDB.MMCIFParser import MMCIFParser\n",
    "from Bio.PDB import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Functions\n",
    "def parse_mmcif_coordinates(mmcif_file_path):\n",
    "    \"\"\"\n",
    "    Parse an mmCIF file and extract atomic coordinates into numpy arrays\n",
    "    \n",
    "    Args:\n",
    "        mmcif_file_path: Path to the .cif file\n",
    "    \n",
    "    Returns:\n",
    "        dict: Contains coordinates, atom names, residue info, etc.\n",
    "    \"\"\"\n",
    "    parser = MMCIFParser(QUIET=True)\n",
    "    structure = parser.get_structure('structure', mmcif_file_path)\n",
    "    \n",
    "    coordinates = []\n",
    "    atom_names = []\n",
    "    residue_names = []\n",
    "    residue_numbers = []\n",
    "    chain_ids = []\n",
    "    \n",
    "    # Extract data from all atoms\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            for residue in chain:\n",
    "                for atom in residue:\n",
    "                    coordinates.append(atom.get_coord())\n",
    "                    atom_names.append(atom.get_name())\n",
    "                    residue_names.append(residue.get_resname())\n",
    "                    residue_numbers.append(residue.get_id()[1])\n",
    "                    chain_ids.append(chain.get_id())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    coord_array = np.array(coordinates)\n",
    "    \n",
    "    return {\n",
    "        'coordinates': coord_array,\n",
    "        'atom_names': np.array(atom_names),\n",
    "        'residue_names': np.array(residue_names),\n",
    "        'residue_numbers': np.array(residue_numbers),\n",
    "        'chain_ids': np.array(chain_ids)\n",
    "    }\n",
    "\n",
    "def calculate_COM(coordinates):\n",
    "    \"\"\"\n",
    "    Calculate the center of mass for a set of coordinates.\n",
    "    \n",
    "    Args:\n",
    "        coordinates: numpy array of shape (N, 3) where N is the number of atoms.\n",
    "    Returns:\n",
    "        numpy array of shape (3,) representing the center of mass.\n",
    "    \"\"\"\n",
    "    return np.mean(coordinates, axis=0)\n",
    "\n",
    "def get_chain_coordinates(mmcif_data, chain_id):\n",
    "    \"\"\"\n",
    "    Extract coordinates for a specific chain\n",
    "    \n",
    "    Args:\n",
    "        mmcif_data: Dictionary from parse_mmcif_coordinates\n",
    "        chain_id: Chain identifier (e.g., 'A', 'B')\n",
    "    \n",
    "    Returns:\n",
    "        dict: Filtered data for the specified chain\n",
    "    \"\"\"\n",
    "    chain_mask = mmcif_data['chain_ids'] == chain_id\n",
    "    \n",
    "    return {\n",
    "        'coordinates': mmcif_data['coordinates'][chain_mask],\n",
    "        'atom_names': mmcif_data['atom_names'][chain_mask],\n",
    "        'residue_names': mmcif_data['residue_names'][chain_mask],\n",
    "        'residue_numbers': mmcif_data['residue_numbers'][chain_mask],\n",
    "        'chain_ids': mmcif_data['chain_ids'][chain_mask]\n",
    "    }\n",
    "\n",
    "def get_residue_coordinates(mmcif_data, chain_id, residue_number):\n",
    "    \"\"\"\n",
    "    Extract coordinates for a specific residue in a specific chain\n",
    "    \n",
    "    Args:\n",
    "        mmcif_data: Dictionary from parse_mmcif_coordinates\n",
    "        chain_id: Chain identifier (e.g., 'A', 'B')\n",
    "        residue_number: Residue number\n",
    "    \n",
    "    Returns:\n",
    "        dict: Filtered data for the specified residue\n",
    "    \"\"\"\n",
    "    residue_mask = (mmcif_data['chain_ids'] == chain_id) & (mmcif_data['residue_numbers'] == residue_number)\n",
    "    \n",
    "    return {\n",
    "        'coordinates': mmcif_data['coordinates'][residue_mask],\n",
    "        'atom_names': mmcif_data['atom_names'][residue_mask],\n",
    "        'residue_names': mmcif_data['residue_names'][residue_mask],\n",
    "        'residue_numbers': mmcif_data['residue_numbers'][residue_mask],\n",
    "        'chain_ids': mmcif_data['chain_ids'][residue_mask]\n",
    "    }\n",
    "\n",
    "def get_residue_range_coordinates(mmcif_data, chain_id, start_res, end_res):\n",
    "    \"\"\"Extract coordinates for a range of residues\"\"\"\n",
    "    range_mask = (mmcif_data['chain_ids'] == chain_id) & \\\n",
    "                 (mmcif_data['residue_numbers'] >= start_res) & \\\n",
    "                 (mmcif_data['residue_numbers'] <= end_res)\n",
    "    \n",
    "    return {\n",
    "        'coordinates': mmcif_data['coordinates'][range_mask],\n",
    "        'atom_names': mmcif_data['atom_names'][range_mask],\n",
    "        'residue_names': mmcif_data['residue_names'][range_mask],\n",
    "        'residue_numbers': mmcif_data['residue_numbers'][range_mask],\n",
    "        'chain_ids': mmcif_data['chain_ids'][range_mask]\n",
    "    }\n",
    "\n",
    "def calculate_distance(coord1, coord2):\n",
    "    \"\"\"\n",
    "    Calculate Euclidean distance between two points.\n",
    "    \n",
    "    Args:\n",
    "        coord1: numpy array of shape (3,)\n",
    "        coord2: numpy array of shape (3,)\n",
    "    \n",
    "    Returns:\n",
    "        float: Euclidean distance\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(coord1 - coord2)\n",
    "\n",
    "def process_all_cif_files(cif_directory, binder_chain, receptor_chain, receptor_residue_range):\n",
    "    \"\"\"\n",
    "    Process all CIF files in a directory and calculate distances between \n",
    "    binder COM and receptor binding site COM\n",
    "    \n",
    "    Args:\n",
    "        cif_directory: Path to directory containing CIF files\n",
    "        binder_chain: Chain ID of the binder (e.g., 'A')\n",
    "        receptor_chain: Chain ID of the receptor (e.g., 'B') \n",
    "        receptor_residue_range: Tuple (start_res, end_res) for binding site\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Results with filename and distance\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Get all .cif files in the directory\n",
    "    cif_files = [f for f in os.listdir(cif_directory) if f.endswith('.cif')]\n",
    "    \n",
    "    print(f\"Found {len(cif_files)} CIF files to process...\")\n",
    "    \n",
    "    for i, filename in enumerate(cif_files):\n",
    "        try:\n",
    "            # Parse the CIF file\n",
    "            file_path = os.path.join(cif_directory, filename)\n",
    "            mmcif_data = parse_mmcif_coordinates(file_path)\n",
    "            \n",
    "            # Get binder chain coordinates\n",
    "            binder_data = get_chain_coordinates(mmcif_data, binder_chain)\n",
    "            \n",
    "            # Get receptor binding site coordinates\n",
    "            receptor_bindsite_data = get_residue_range_coordinates(\n",
    "                mmcif_data, receptor_chain, \n",
    "                receptor_residue_range[0], receptor_residue_range[1]\n",
    "            )\n",
    "            \n",
    "            # Calculate center of mass for both\n",
    "            if len(binder_data['coordinates']) > 0 and len(receptor_bindsite_data['coordinates']) > 0:\n",
    "                binder_com = calculate_COM(binder_data['coordinates'])\n",
    "                receptor_bindsite_com = calculate_COM(receptor_bindsite_data['coordinates'])\n",
    "                \n",
    "                # Calculate distance between COMs\n",
    "                distance = calculate_distance(binder_com, receptor_bindsite_com)\n",
    "                \n",
    "                results.append({\n",
    "                    'file_name': filename,\n",
    "                    'binder_chain': binder_chain,\n",
    "                    'receptor_chain': receptor_chain,\n",
    "                    'binding_site_residues': f\"{receptor_residue_range[0]}-{receptor_residue_range[1]}\",\n",
    "                    'distance_angstroms': distance,\n",
    "                    'binder_atom_count': len(binder_data['coordinates']),\n",
    "                    'bindsite_atom_count': len(receptor_bindsite_data['coordinates'])\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Warning: Missing chains in {filename}\")\n",
    "                results.append({\n",
    "                    'file_name': filename,\n",
    "                    'binder_chain': binder_chain,\n",
    "                    'receptor_chain': receptor_chain,\n",
    "                    'binding_site_residues': f\"{receptor_residue_range[0]}-{receptor_residue_range[1]}\",\n",
    "                    'distance_angstroms': np.nan,\n",
    "                    'binder_atom_count': len(binder_data['coordinates']) if 'coordinates' in binder_data else 0,\n",
    "                    'bindsite_atom_count': len(receptor_bindsite_data['coordinates']) if 'coordinates' in receptor_bindsite_data else 0\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "            results.append({\n",
    "                'file_name': filename,\n",
    "                'binder_chain': binder_chain,\n",
    "                'receptor_chain': receptor_chain,\n",
    "                'binding_site_residues': f\"{receptor_residue_range[0]}-{receptor_residue_range[1]}\",\n",
    "                'distance_angstroms': np.nan,\n",
    "                'binder_atom_count': 0,\n",
    "                'bindsite_atom_count': 0\n",
    "            })\n",
    "        \n",
    "        # Progress update\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(cif_files)} files...\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "def get_chain_sequence(mmcif_data, chain_id):\n",
    "    \"\"\"\n",
    "    Extract amino acid sequence from a specific chain\n",
    "    \n",
    "    Args:\n",
    "        mmcif_data: Dictionary from parse_mmcif_coordinates\n",
    "        chain_id: Chain identifier (e.g., 'A', 'B')\n",
    "    \n",
    "    Returns:\n",
    "        dict: Contains sequence, residue numbers, and residue names\n",
    "    \"\"\"\n",
    "    # Filter data for the specified chain\n",
    "    chain_mask = mmcif_data['chain_ids'] == chain_id\n",
    "    \n",
    "    chain_residue_numbers = mmcif_data['residue_numbers'][chain_mask]\n",
    "    chain_residue_names = mmcif_data['residue_names'][chain_mask]\n",
    "    \n",
    "    # Get unique residues in order\n",
    "    unique_residues = []\n",
    "    seen_residues = set()\n",
    "    \n",
    "    for res_num, res_name in zip(chain_residue_numbers, chain_residue_names):\n",
    "        residue_key = (res_num, res_name)\n",
    "        if residue_key not in seen_residues:\n",
    "            unique_residues.append((res_num, res_name))\n",
    "            seen_residues.add(residue_key)\n",
    "    \n",
    "    # Sort by residue number\n",
    "    unique_residues.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Three-letter to one-letter amino acid code mapping\n",
    "    aa_code_map = {\n",
    "        'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D', 'CYS': 'C',\n",
    "        'GLU': 'E', 'GLN': 'Q', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I',\n",
    "        'LEU': 'L', 'LYS': 'K', 'MET': 'M', 'PHE': 'F', 'PRO': 'P',\n",
    "        'SER': 'S', 'THR': 'T', 'TRP': 'W', 'TYR': 'Y', 'VAL': 'V',\n",
    "        # Common modified amino acids\n",
    "        'MSE': 'M',  # Selenomethionine\n",
    "        'CSE': 'C',  # Selenocysteine\n",
    "        'PYL': 'O',  # Pyrrolysine\n",
    "        'SEC': 'U',  # Selenocysteine\n",
    "    }\n",
    "    \n",
    "    # Convert to one-letter codes\n",
    "    sequence = \"\"\n",
    "    residue_numbers = []\n",
    "    residue_names = []\n",
    "    \n",
    "    for res_num, res_name in unique_residues:\n",
    "        if res_name in aa_code_map:\n",
    "            sequence += aa_code_map[res_name]\n",
    "            residue_numbers.append(res_num)\n",
    "            residue_names.append(res_name)\n",
    "        else:\n",
    "            # Handle non-standard residues\n",
    "            sequence += 'X'  # Unknown amino acid\n",
    "            residue_numbers.append(res_num)\n",
    "            residue_names.append(res_name)\n",
    "            print(f\"Warning: Unknown residue {res_name} at position {res_num} in chain {chain_id}\")\n",
    "    \n",
    "    return {\n",
    "        'sequence': sequence,\n",
    "        'residue_numbers': residue_numbers,\n",
    "        'residue_names': residue_names,\n",
    "        'chain_id': chain_id,\n",
    "        'length': len(sequence)\n",
    "    }\n",
    "\n",
    "def get_sequence_from_file(mmcif_file_path, chain_id):\n",
    "    \"\"\"\n",
    "    Extract amino acid sequence from a CIF file for a specific chain\n",
    "    \n",
    "    Args:\n",
    "        mmcif_file_path: Path to the .cif file\n",
    "        chain_id: Chain identifier (e.g., 'A', 'B')\n",
    "    \n",
    "    Returns:\n",
    "        dict: Contains sequence information\n",
    "    \"\"\"\n",
    "    # Parse the CIF file\n",
    "    mmcif_data = parse_mmcif_coordinates(mmcif_file_path)\n",
    "    \n",
    "    # Extract sequence for the specified chain\n",
    "    sequence_data = get_chain_sequence(mmcif_data, chain_id)\n",
    "    \n",
    "    return sequence_data\n",
    "\n",
    "def extract_sequences_from_all_files(cif_directory, chain_id):\n",
    "    \"\"\"\n",
    "    Extract sequences from all CIF files in a directory for a specific chain\n",
    "    \n",
    "    Args:\n",
    "        cif_directory: Path to directory containing CIF files\n",
    "        chain_id: Chain identifier (e.g., 'A', 'B')\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Results with filename and sequence data\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Get all .cif files in the directory\n",
    "    cif_files = [f for f in os.listdir(cif_directory) if f.endswith('.cif')]\n",
    "    \n",
    "    print(f\"Extracting sequences from {len(cif_files)} CIF files for chain {chain_id}...\")\n",
    "    \n",
    "    for i, filename in enumerate(cif_files):\n",
    "        try:\n",
    "            file_path = os.path.join(cif_directory, filename)\n",
    "            sequence_data = get_sequence_from_file(file_path, chain_id)\n",
    "            \n",
    "            results.append({\n",
    "                'file_name': filename,\n",
    "                'chain_id': chain_id,\n",
    "                'sequence': sequence_data['sequence'],\n",
    "                'sequence_length': sequence_data['length'],\n",
    "                'residue_count': len(sequence_data['residue_numbers']),\n",
    "                'first_residue': sequence_data['residue_numbers'][0] if sequence_data['residue_numbers'] else None,\n",
    "                'last_residue': sequence_data['residue_numbers'][-1] if sequence_data['residue_numbers'] else None\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "            results.append({\n",
    "                'file_name': filename,\n",
    "                'chain_id': chain_id,\n",
    "                'sequence': '',\n",
    "                'sequence_length': 0,\n",
    "                'residue_count': 0,\n",
    "                'first_residue': None,\n",
    "                'last_residue': None\n",
    "            })\n",
    "        \n",
    "        # Progress update\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(cif_files)} files...\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def extract_rank_number(filename):\n",
    "    \"\"\"Extract rank number from filename like 'rank0073_GLP1_ICL3_1stRun_3780.cif' -> 73\"\"\"\n",
    "    try:\n",
    "        if filename.startswith('rank'):\n",
    "            rank_part = filename.split('_')[0]  # Get the 'rank0073' part\n",
    "            rank_number = rank_part.replace('rank', '')  # Remove 'rank' to get '0073'\n",
    "            return int(rank_number)  # Convert '0073' to 73\n",
    "        else:\n",
    "            return float('inf')  # Put non-rank files at the end\n",
    "    except:\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c2f4d",
   "metadata": {},
   "source": [
    "User defined Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67de1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chain ID of the binder (usually chain A for most cases)\n",
    "chain_ID_binder = 'A'\n",
    "chain_ID_receptor = 'B'\n",
    "\n",
    "# Define the residue range of the binding site of the receptor\n",
    "residue_range = (332, 346) \n",
    "\n",
    "# CIF file path, place where all the final ranked designs are stored\n",
    "cif_file_path = 'final_ranked_designs/final_100_designs/'\n",
    "\n",
    "# Output path for filtered designs\n",
    "output_path = 'bindsite_filtered_designs/'\n",
    "\n",
    "# Distance threshold for binding site filtering\n",
    "distance_threshold = 25.0  # in Angstroms\n",
    "\n",
    "# BoltzGen Filtered CSV File\n",
    "boltzgen_csv = 'final_ranked_designs/final_designs_metrics_100.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc2fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all CIF files with the defined parameters\n",
    "print(\"Processing CIF files...\")\n",
    "print(f\"Binder chain: {chain_ID_binder}\")\n",
    "print(f\"Receptor chain: {chain_ID_receptor}\")\n",
    "print(f\"Binding site residue range: {residue_range}\")\n",
    "print(f\"Distance threshold: {distance_threshold} Å\")\n",
    "\n",
    "# Calculate distances for all files\n",
    "distance_df = process_all_cif_files(\n",
    "    cif_file_path, \n",
    "    chain_ID_binder, \n",
    "    chain_ID_receptor, \n",
    "    residue_range\n",
    ")\n",
    "\n",
    "print(f\"\\nCompleted processing. Results shape: {distance_df.shape}\")\n",
    "print(\"\\nFirst 5 results:\")\n",
    "print(distance_df.head())\n",
    "\n",
    "print(f\"\\nDistance statistics:\")\n",
    "print(distance_df['distance_angstroms'].describe())\n",
    "\n",
    "# Filter designs based on distance threshold\n",
    "filtered_df = distance_df[distance_df['distance_angstroms'] <= distance_threshold].copy()\n",
    "\n",
    "print(f\"\\nFiltering results:\")\n",
    "print(f\"Total designs processed: {len(distance_df)}\")\n",
    "print(f\"Designs within {distance_threshold} Å: {len(filtered_df)}\")\n",
    "print(f\"Percentage passing filter: {len(filtered_df)/len(distance_df)*100:.1f}%\")\n",
    "\n",
    "# Sort by distance (closest first)\n",
    "filtered_df = filtered_df.sort_values('distance_angstroms').reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTop 10 closest designs:\")\n",
    "print(filtered_df[['file_name', 'distance_angstroms']].head(10))\n",
    "\n",
    "# Save results to CSV files\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Save all results\n",
    "all_results_file = os.path.join(output_path, 'all_distance_calculations.csv')\n",
    "distance_df.to_csv(all_results_file, index=False)\n",
    "print(f\"\\nAll results saved to: {all_results_file}\")\n",
    "\n",
    "# Display summary statistics for filtered designs\n",
    "print(f\"\\nFiltered designs distance statistics:\")\n",
    "print(filtered_df['distance_angstroms'].describe())\n",
    "\n",
    "# Copy filtered CIF files to output directory\n",
    "for filename in filtered_df['file_name']:\n",
    "    src_path = os.path.join(cif_file_path, filename)\n",
    "    dest_path = os.path.join(output_path, filename)\n",
    "    if os.path.exists(src_path):\n",
    "        shutil.copy(src_path, dest_path)\n",
    "print(f\"\\nFiltered CIF files copied to: {output_path}\")\n",
    "\n",
    "# Plot histogram of distances for all designs\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(distance_df['distance_angstroms'].dropna(), bins=50, color='skyblue', edgecolor='black')\n",
    "plt.axvline(distance_threshold, color='red', linestyle='dashed', linewidth=1)\n",
    "plt.title('Distribution of Binder to Binding Site Distances')\n",
    "plt.xlabel('Distance (Å)')\n",
    "plt.ylabel('Number of Designs')\n",
    "\n",
    "plt.savefig(os.path.join(output_path, 'distance_distribution_histogram.tiff'), dpi=200)\n",
    "print(f\"Distance distribution histogram saved to: {os.path.join(output_path, 'distance_distribution_histogram.tiff')}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Extract sequences from filtered binders and append to filtered_df\n",
    "print(f\"\\nExtracting binder sequences for {len(filtered_df)} filtered designs...\")\n",
    "\n",
    "sequences_data = []\n",
    "for i, row in filtered_df.iterrows():\n",
    "    filename = row['file_name']\n",
    "    try:\n",
    "        # Get the full path to the CIF file\n",
    "        file_path = os.path.join(cif_file_path, filename)\n",
    "        \n",
    "        # Extract sequence for the binder chain\n",
    "        sequence_data = get_sequence_from_file(file_path, chain_ID_binder)\n",
    "        \n",
    "        sequences_data.append({\n",
    "            'file_name': filename,\n",
    "            'binder_sequence': sequence_data['sequence'],\n",
    "            'binder_length': sequence_data['length'],\n",
    "            'binder_first_residue': sequence_data['residue_numbers'][0] if sequence_data['residue_numbers'] else None,\n",
    "            'binder_last_residue': sequence_data['residue_numbers'][-1] if sequence_data['residue_numbers'] else None\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting sequence from {filename}: {str(e)}\")\n",
    "        sequences_data.append({\n",
    "            'file_name': filename,\n",
    "            'binder_sequence': '',\n",
    "            'binder_length': 0,\n",
    "            'binder_first_residue': None,\n",
    "            'binder_last_residue': None\n",
    "        })\n",
    "    \n",
    "    # Progress update\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Processed sequences for {i + 1}/{len(filtered_df)} files...\")\n",
    "\n",
    "# Convert sequences data to DataFrame\n",
    "sequences_df = pd.DataFrame(sequences_data)\n",
    "\n",
    "# Merge with filtered_df\n",
    "filtered_df_with_sequences = filtered_df.merge(sequences_df, on='file_name', how='left')\n",
    "\n",
    "print(f\"\\nSequence extraction completed!\")\n",
    "print(f\"Enhanced dataframe shape: {filtered_df_with_sequences.shape}\")\n",
    "print(f\"New columns added: {[col for col in filtered_df_with_sequences.columns if col not in filtered_df.columns]}\")\n",
    "\n",
    "# Display some sequence statistics\n",
    "if len(sequences_df) > 0:\n",
    "    valid_sequences = sequences_df[sequences_df['binder_length'] > 0]\n",
    "    if len(valid_sequences) > 0:\n",
    "        print(f\"\\nBinder sequence statistics:\")\n",
    "        print(f\"Average length: {valid_sequences['binder_length'].mean():.1f}\")\n",
    "        print(f\"Min length: {valid_sequences['binder_length'].min()}\")\n",
    "        print(f\"Max length: {valid_sequences['binder_length'].max()}\")\n",
    "        \n",
    "        print(f\"\\nFirst 5 binder sequences:\")\n",
    "        for idx, row in valid_sequences.head().iterrows():\n",
    "            print(f\"{row['file_name']}: {row['binder_sequence'][:50]}{'...' if len(row['binder_sequence']) > 50 else ''}\")\n",
    "\n",
    "# Reorder by rank number in filename (rank0001_XXX.cif to rank_XXXX_XXX.cif)\n",
    "print(f\"\\nReordering results by rank number...\")\n",
    "\n",
    "# Add rank column for sorting\n",
    "filtered_df_with_sequences['rank_number'] = filtered_df_with_sequences['file_name'].apply(extract_rank_number)\n",
    "\n",
    "# Sort by rank number\n",
    "filtered_df_with_sequences_sorted = filtered_df_with_sequences.sort_values('rank_number').reset_index(drop=True)\n",
    "\n",
    "# Save the reordered results\n",
    "reordered_results_file = os.path.join(output_path, f'filtered_designs_with_sequences_ranked_{distance_threshold}A.csv')\n",
    "filtered_df_with_sequences_sorted.to_csv(reordered_results_file, index=False)\n",
    "print(f\"Reordered results saved to: {reordered_results_file}\")\n",
    "\n",
    "print(f\"\\nFirst 10 files in reordered results:\")\n",
    "print(filtered_df_with_sequences_sorted[['file_name', 'distance_angstroms']].head(10))\n",
    "\n",
    "# Update the main filtered_df to include sequences and proper ordering\n",
    "filtered_df = filtered_df_with_sequences_sorted.copy()\n",
    "print(f\"\\nfiltered_df updated with sequence information and rank ordering\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BoltzGen_Tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
